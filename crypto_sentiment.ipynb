{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 12 - Tales from the Crypto\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentiment Analysis\n",
    "\n",
    "Use the [newsapi](https://newsapi.org/) to pull the latest news articles for Bitcoin and Ethereum and create a DataFrame of sentiment scores for each coin.\n",
    "\n",
    "Use descriptive statistics to answer the following questions:\n",
    "1. Which coin had the highest mean positive score?\n",
    "Euthereum has the the highest mean positive score \n",
    "2. Which coin had the highest negative score?\n",
    "Bitcoin has the highest negative score \n",
    "3. Which coin had the highest positive score?\n",
    "Euthereum has the highest postive score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/diopmouhamadoulamine/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: NLTK in /Users/diopmouhamadoulamine/.local/lib/python3.8/site-packages (3.6.5)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from NLTK) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/diopmouhamadoulamine/.local/lib/python3.8/site-packages (from NLTK) (2021.11.10)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from NLTK) (4.50.2)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.8/site-packages (from NLTK) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your api key environment variable\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"NEWS_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newsapi in /opt/anaconda3/lib/python3.8/site-packages (0.1.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from newsapi) (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->newsapi) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from requests->newsapi) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->newsapi) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->newsapi) (1.26.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install newsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newsapi-python in /opt/anaconda3/lib/python3.8/site-packages (0.2.6)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from newsapi-python) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0->newsapi-python) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0->newsapi-python) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0->newsapi-python) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0->newsapi-python) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install newsapi-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a newsapi client\n",
    "from newsapi import NewsApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Bitcoin news articles\n",
    "BTC_headlines = newsapi.get_everything(\n",
    "    q=\"bitcoin\",\n",
    "    language=\"en\",\n",
    "    sort_by=\"relevancy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Ethereum news articles\n",
    "ETH_headlines = newsapi.get_everything(\n",
    "    q=\"ethereum\",\n",
    "    language=\"en\",\n",
    "    sort_by=\"relevancy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bitcoin sentiment scores DataFrame\n",
    "sentiments = []\n",
    "\n",
    "for articles inBTC_headlines[\"articles\"]:\n",
    "    try:\n",
    "        text = articles[\"content\"]\n",
    "        results = analyzer.polarity_scores(text)\n",
    "        compound = results[\"compound\"]\n",
    "        pos = results[\"pos\"]\n",
    "        neu = results[\"neu\"]\n",
    "        neg = results[\"neg\"]\n",
    "\n",
    "        sentiments.append({\n",
    "            \"text\": text,\n",
    "            \"Compound\": compound,\n",
    "            \"Positive\": pos,\n",
    "            \"Negative\": neg,\n",
    "            \"Neutral\": neu,\n",
    "        })\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "BTC  = pd.DataFrame(sentiments)\n",
    "BTC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ethereum sentiment scores DataFrame\n",
    "sentiments = []\n",
    "\n",
    "for articles in ETH_headlines[\"articles\"]:\n",
    "    try:\n",
    "        text = articles[\"content\"]\n",
    "        results = analyzer.polarity_scores(text)\n",
    "        compound = results[\"compound\"]\n",
    "        pos = results[\"pos\"]\n",
    "        neu = results[\"neu\"]\n",
    "        neg = results[\"neg\"]\n",
    "\n",
    "        sentiments.append({\n",
    "            \"text\": text,\n",
    "            \"Compound\": compound,\n",
    "            \"Positive\": pos,\n",
    "            \"Negative\": neg,\n",
    "            \"Neutral\": neu,\n",
    "        })\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "ETH  = pd.DataFrame(sentiments)\n",
    "ETH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the Bitcoin Sentiment\n",
    "BTC.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the Ethereum Sentiment\n",
    "ETH.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "**Important note:** The sample answers may vary depending on when this code is running since news may change over time.\n",
    "\n",
    "Q: Which coin had the highest mean positive score?\n",
    "\n",
    "A: Ethereum had a slightly higher mean positive score\n",
    "\n",
    "Q: Which coin had the highest compound score?\n",
    "\n",
    "A: Bitcoin had the highest compound score\n",
    "\n",
    "Q. Which coin had the highest positive score?\n",
    "\n",
    "A: Bitcoin had the highest Positive score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Natural Language Processing\n",
    "---\n",
    "###   Tokenize\n",
    "\n",
    "In this section, you will use NLTK and Python to tokenize the text for each coin. Be sure to:\n",
    "1. Lowercase each word,\n",
    "2. Remove punctuation.\n",
    "3. Remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the lemmatizer\n",
    "wnl = WordNetLemmatizer() \n",
    "\n",
    "# Create a list of stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Expand the default stopwords list if necessary\n",
    "stop.append(\"u\")\n",
    "stop.append(\"it'\")\n",
    "stop.append(\"'s\")\n",
    "stop.append(\"n't\")\n",
    "stop.append('â€¦')\n",
    "stop.append(\"\\`\")\n",
    "stop.append('``')\n",
    "stop.append('char')\n",
    "stop.append(\"''\")\n",
    "stop = set(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the tokenizer function\n",
    "def tokenizer(text):\n",
    "    \"\"\"Tokenizes text.\"\"\"\n",
    "    \n",
    "    # Create a list of the words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Convert the words to lowercase\n",
    "    words = list(filter(lambda w: w.lower(), words))\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    words = list(filter(lambda t: t not in punctuation, words))\n",
    "    \n",
    "    # Remove the stopwords\n",
    "    words = list(filter(lambda t: t.lower() not in stop, words))\n",
    "    \n",
    "    # Lemmatize Words into root words\n",
    "    tokens = [wnl.lemmatize(word) for word in words]\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for Bitcoin\n",
    "BTC[\"tokens\"] = BTC.text.apply(tokenizer)\n",
    "BTC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for Ethereum\n",
    "ETH[\"tokens\"] = ETH.text.apply(tokenizer)\n",
    "ETH.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGrams and Frequency Analysis\n",
    "\n",
    "In this section you will look at the ngrams and word frequency for each coin. \n",
    "\n",
    "1. Use NLTK to produce the n-grams for N = 2. \n",
    "2. List the top 10 words for each coin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Bitcoin N-grams where N=2\n",
    "N = 2\n",
    "grams = ngrams(tokenizer(BTC.text.str.cat()), N)\n",
    "Counter(grams).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Ethereum N-grams where N=2\n",
    "N = 2\n",
    "grams = ngrams(tokenizer(ETH.text.str.cat()), N)\n",
    "Counter(grams).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function token_count generates the top 10 words for a given coin\n",
    "def token_count(tokens, N=3):\n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\n",
    "    return Counter(tokens).most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use token_count to get the top 10 words for Bitcoin\n",
    "all_tokens = tokenizer(BTC.text.str.cat())\n",
    "token_count(all_tokens, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use token_count to get the top 10 words for Ethereum\n",
    "all_tokens = tokenizer(ETH.text.str.cat())\n",
    "token_count(all_tokens, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds\n",
    "\n",
    "In this section, you will generate word clouds for each coin to summarize the news for each coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [20.0, 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud(text, title=\"\"):\n",
    "    df_cloud = WordCloud(width=500, colormap='RdYlBu').generate(text)\n",
    "    plt.imshow(df_cloud)\n",
    "    plt.axis(\"off\")\n",
    "    fontdict = {\"fontsize\": 48, \"fontweight\" : \"bold\"}\n",
    "    plt.title(title, fontdict=fontdict)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(BTC.text.str.cat(), title=\"Bitcoin Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(ETH.text.str.cat(), title=\"Ethereum Word Cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Named Entity Recognition\n",
    "\n",
    "In this section, you will build a named entity recognition model for both coins and visualize the tags using SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the language model for SpaCy if needed\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the bitcoin text together\n",
    "all_BTC_text = BTC.text.str.cat()\n",
    "all_BTC_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NER processor on all of the text\n",
    "doc = nlp(all_BTC_text)\n",
    "\n",
    "# Add a title to the document\n",
    "doc.user_data[\"title\"] = \"Bitcoin NER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the bitcoin text together\n",
    "all_ETH_text = ETH.text.str.cat()\n",
    "all_ETH_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NER processor on all of the text\n",
    "ETH_doc = nlp(all_ETH_text)\n",
    "\n",
    "# Add a title to the document\n",
    "ETH_doc.user_data[\"title\"] = \"Ethereum NER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "displacy.render(ETH_doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Entities\n",
    "for ent in ETH_doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
